{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31650557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "## Load datasets\n",
    "fake = pd.read_csv('fake.csv')\n",
    "true = pd.read_csv('true.csv')\n",
    "\n",
    "# add labels for verification during testing\n",
    "fake['label'] = 0\n",
    "true['label'] = 1\n",
    "\n",
    "# combine datasets\n",
    "data = pd.concat([fake, true]).reset_index(drop=True)\n",
    "\n",
    "# only use relevant columns\n",
    "data = data[['title', 'text', 'label']]\n",
    "\n",
    "# combine title with text to ease processing\n",
    "data['combined'] = data['title'] + \" \" + data['text']\n",
    "\n",
    "# define common words that will not be considered\n",
    "common_words = set([\n",
    "    \"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\n",
    "    \"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\n",
    "    \"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
    "    \"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\n",
    "    \"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\n",
    "    \"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\n",
    "    \"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\n",
    "    \"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\n",
    "    \"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\n",
    "    \"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\n",
    "    \"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\n",
    "    \"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"\n",
    "])\n",
    "\n",
    "# lowercase all text and remove punctuation and common words\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    # remove punctuation one char at a time\n",
    "    for c in text:\n",
    "        if c in string.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "    # remove common words\n",
    "    tokenized_text = text.split() # split text into each individual word\n",
    "    for word in tokenized_text:\n",
    "        if word in stopwords:\n",
    "            text = text.replace(word, \"\")\n",
    "    return \" \".join(tokenized_text) # stitches twords back into one cohesive text, separating with \" \"\n",
    "\n",
    "# apply preprocessing to data\n",
    "data['preproccessed'] = data[['combined']].apply(preprocess_text)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
